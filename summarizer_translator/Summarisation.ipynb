{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "4RI__4nZZnoC",
        "outputId": "88712084-1f0d-42a3-a4ff-764e87e6d166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://88f3b79dd2ca9ebe34.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://88f3b79dd2ca9ebe34.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Load models\n",
        "summarizer_model = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "question_gen_model = pipeline(\"text2text-generation\", model=\"iarfmoose/t5-base-question-generator\")\n",
        "\n",
        "# Define function for Gradio\n",
        "def generate_summary_and_questions(text):\n",
        "    # Summarize\n",
        "    summary = summarizer_model(text, max_length=80, min_length=40, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    # Generate questions\n",
        "    questions = question_gen_model(text)[0]['generated_text']\n",
        "\n",
        "    return summary, questions\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_summary_and_questions,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Paste your notes here...\"),\n",
        "    outputs=[gr.Textbox(label=\"Summary\"), gr.Textbox(label=\"Generated Questions\")],\n",
        "    title=\"Smart Study Assistant\",\n",
        "    description=\"Summarizes your notes and generates study questions using AI.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}